{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Breast Cancer ML Classification\n",
        "\n",
        "This notebook demonstrates multi-algorithm classification for breast cancer diagnosis.\n",
        "\n",
        "## Contents\n",
        "1. Data Loading & Exploration\n",
        "2. Preprocessing & Feature Engineering\n",
        "3. Model Training & Comparison\n",
        "4. Evaluation & Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('../src')\n",
        "\n",
        "from data_processor import DataProcessor\n",
        "from model_trainer import ModelTrainer\n",
        "from evaluator import ModelEvaluator\n",
        "from visualizer import Visualizer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print('Modules loaded!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading & Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize processor and load data\n",
        "processor = DataProcessor()\n",
        "processor.load_from_sklearn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View summary\n",
        "processor.get_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize target distribution\n",
        "viz = Visualizer()\n",
        "viz.plot_target_distribution(processor.df['diagnosis'].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detect and handle outliers\n",
        "processor.detect_outliers(method='iqr')\n",
        "processor.handle_outliers(method='clip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scale features\n",
        "processor.scale_features(method='minmax')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare train/test split\n",
        "X_train, X_test, y_train, y_test = processor.prepare_for_training(test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize trainer and add all models\n",
        "trainer = ModelTrainer(cv_folds=5)\n",
        "trainer.add_default_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train all models with GridSearchCV\n",
        "results = trainer.train_all(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get best model\n",
        "best_name, best_model = trainer.get_best_model()\n",
        "print(f\"Best Model: {best_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare all models\n",
        "comparison = trainer.evaluate_on_test(X_test, y_test)\n",
        "print(comparison)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detailed evaluation\n",
        "evaluator = ModelEvaluator()\n",
        "result = evaluator.evaluate(best_model, X_test, y_test, best_name)\n",
        "evaluator.print_summary(best_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "viz.plot_confusion_matrix(result.confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model Comparison\n",
        "comparison_df = trainer.get_comparison_dataframe()\n",
        "viz.plot_model_comparison(comparison_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Medical Interpretation\n",
        "interpretation = evaluator.get_medical_interpretation(result)\n",
        "for key, value in interpretation.items():\n",
        "    print(f\"{key}:\")\n",
        "    print(f\"  {value}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "- Data preprocessing with outlier handling\n",
        "- Training 6 ML algorithms with GridSearchCV\n",
        "- Model comparison and evaluation\n",
        "- Medical interpretation of results"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
